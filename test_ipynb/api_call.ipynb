{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d6658c8",
   "metadata": {},
   "source": [
    "# 该脚本用来测试链接魔搭api服务是否通畅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97163dd1",
   "metadata": {},
   "source": [
    "## 通过load dotenv加载环境变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b076350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abfaea1",
   "metadata": {},
   "source": [
    "## 查看导入的环境变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97746f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ee879477-517c-4899-9793-de2b20aad7ba\n",
      "https://api-inference.modelscope.cn/v1/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.environ.get(\"OPENAI_API_KEY\"))\n",
    "print(os.environ.get(\"OPENAI_BASE_URL\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e81a748",
   "metadata": {},
   "source": [
    "## 调用测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161d8a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下是一个使用 Python 实现的快速排序（Quick Sort）算法，采用 **列表推导式** 的方式编写，代码简洁且易于理解，适合教学和初学者参考。\n",
      "\n",
      "---\n",
      "\n",
      "### ✅ 快速排序（Quick Sort）Python 实现\n",
      "\n",
      "```python\n",
      "def quicksort(arr):\n",
      "    if len(arr) <= 1:\n",
      "        return arr  # 基本情况：数组长度为0或1时已有序\n",
      "\n",
      "    # 选择中间元素作为基准值（pivot）\n",
      "    pivot = arr[len(arr) // 2]\n",
      "\n",
      "    # 将数组分为三部分：\n",
      "    # - 小于 pivot 的元素\n",
      "    # - 等于 pivot 的元素（用于处理重复值）\n",
      "    # - 大于 pivot 的元素\n",
      "    left = [x for x in arr if x < pivot]\n",
      "    middle = [x for x in arr if x == pivot]\n",
      "    right = [x for x in arr if x > pivot]\n",
      "\n",
      "    # 递归排序左右部分，并将结果合并\n",
      "    return quicksort(left) + middle + quicksort(right)\n",
      "\n",
      "# 测试用例\n",
      "if __name__ == \"__main__\":\n",
      "    arr = [3, 6, 8, 10, 1, 2, 1]\n",
      "    sorted_arr = quicksort(arr)\n",
      "    print(\"排序结果:\", sorted_arr)\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### 🧠 算法说明\n",
      "\n",
      "- **分治策略**：将数组划分为三部分（小于、等于、大于基准值），递归排序左右部分。\n",
      "- **基准值选择**：选择数组中间元素作为 pivot，有助于在多数情况下保持平衡划分。\n",
      "- **时间复杂度**：\n",
      "  - 平均情况：`O(n log n)`\n",
      "  - 最坏情况（如每次选择最差的 pivot）：`O(n^2)`，但可以通过随机选择 pivot 改善。\n",
      "- **空间复杂度**：`O(n)`，因为使用了额外的列表存储 `left`、`middle` 和 `right`。\n",
      "\n",
      "---\n",
      "\n",
      "### 🔁 可选改进：原地排序版本\n",
      "\n",
      "如果你想实现 **原地排序（in-place）** 的快速排序，可以使用类似 Lomuto 或 Hoare 分区的方式。该实现更高效，但代码略复杂。如果你需要这个版本，也可以继续提问。\n",
      "\n",
      "---\n",
      "\n",
      "### 📌 示例输出\n",
      "\n",
      "运行上述代码后，输出为：\n",
      "\n",
      "```\n",
      "排序结果: [1, 1, 2, 3, 6, 8, 10]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "这个实现非常适合用于教学和理解快速排序的基本思想。如果你希望进一步优化（如随机选择 pivot、原地排序等），也可以根据需求进行调整。"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen3-235B-A22B\", # ModleScope Model-Id\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': 'You are a helpful assistant.'\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': '用python写一下快排'\n",
    "        }\n",
    "    ],\n",
    "    stream=True,\n",
    "    extra_body={\n",
    "        \"enable_thinking\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.choices[0].delta.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86fb6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.Stream at 0x7f47426c2ba0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe301729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stream :: None\n"
     ]
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "\n",
    "lite = LiteLlm(model=\"openai/Qwen/Qwen3-235B-A22B\", api_base=os.environ.get(\"OPENAI_BASE_URL\"),stream=True, api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "# lite.llm_client.chat()\n",
    "\n",
    "# openai call\n",
    "response = completion(\n",
    "    stream=True,\n",
    "    model = \"openai/Qwen/Qwen3-235B-A22B\", llm_provider=\"openai\",\n",
    "    messages=[{ \"content\": \"Hello, how are you?\",\"role\": \"user\"}]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
