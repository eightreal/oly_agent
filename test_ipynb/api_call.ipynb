{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d6658c8",
   "metadata": {},
   "source": [
    "# è¯¥è„šæœ¬ç”¨æ¥æµ‹è¯•é“¾æ¥é­”æ­apiæœåŠ¡æ˜¯å¦é€šç•…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97163dd1",
   "metadata": {},
   "source": [
    "## é€šè¿‡load dotenvåŠ è½½ç¯å¢ƒå˜é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b076350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abfaea1",
   "metadata": {},
   "source": [
    "## æŸ¥çœ‹å¯¼å…¥çš„ç¯å¢ƒå˜é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97746f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ee879477-517c-4899-9793-de2b20aad7ba\n",
      "https://api-inference.modelscope.cn/v1/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.environ.get(\"OPENAI_API_KEY\"))\n",
    "print(os.environ.get(\"OPENAI_BASE_URL\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e81a748",
   "metadata": {},
   "source": [
    "## è°ƒç”¨æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161d8a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä»¥ä¸‹æ˜¯ä¸€ä¸ªä½¿ç”¨ Python å®ç°çš„å¿«é€Ÿæ’åºï¼ˆQuick Sortï¼‰ç®—æ³•ï¼Œé‡‡ç”¨ **åˆ—è¡¨æ¨å¯¼å¼** çš„æ–¹å¼ç¼–å†™ï¼Œä»£ç ç®€æ´ä¸”æ˜“äºç†è§£ï¼Œé€‚åˆæ•™å­¦å’Œåˆå­¦è€…å‚è€ƒã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### âœ… å¿«é€Ÿæ’åºï¼ˆQuick Sortï¼‰Python å®ç°\n",
      "\n",
      "```python\n",
      "def quicksort(arr):\n",
      "    if len(arr) <= 1:\n",
      "        return arr  # åŸºæœ¬æƒ…å†µï¼šæ•°ç»„é•¿åº¦ä¸º0æˆ–1æ—¶å·²æœ‰åº\n",
      "\n",
      "    # é€‰æ‹©ä¸­é—´å…ƒç´ ä½œä¸ºåŸºå‡†å€¼ï¼ˆpivotï¼‰\n",
      "    pivot = arr[len(arr) // 2]\n",
      "\n",
      "    # å°†æ•°ç»„åˆ†ä¸ºä¸‰éƒ¨åˆ†ï¼š\n",
      "    # - å°äº pivot çš„å…ƒç´ \n",
      "    # - ç­‰äº pivot çš„å…ƒç´ ï¼ˆç”¨äºå¤„ç†é‡å¤å€¼ï¼‰\n",
      "    # - å¤§äº pivot çš„å…ƒç´ \n",
      "    left = [x for x in arr if x < pivot]\n",
      "    middle = [x for x in arr if x == pivot]\n",
      "    right = [x for x in arr if x > pivot]\n",
      "\n",
      "    # é€’å½’æ’åºå·¦å³éƒ¨åˆ†ï¼Œå¹¶å°†ç»“æœåˆå¹¶\n",
      "    return quicksort(left) + middle + quicksort(right)\n",
      "\n",
      "# æµ‹è¯•ç”¨ä¾‹\n",
      "if __name__ == \"__main__\":\n",
      "    arr = [3, 6, 8, 10, 1, 2, 1]\n",
      "    sorted_arr = quicksort(arr)\n",
      "    print(\"æ’åºç»“æœ:\", sorted_arr)\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ§  ç®—æ³•è¯´æ˜\n",
      "\n",
      "- **åˆ†æ²»ç­–ç•¥**ï¼šå°†æ•°ç»„åˆ’åˆ†ä¸ºä¸‰éƒ¨åˆ†ï¼ˆå°äºã€ç­‰äºã€å¤§äºåŸºå‡†å€¼ï¼‰ï¼Œé€’å½’æ’åºå·¦å³éƒ¨åˆ†ã€‚\n",
      "- **åŸºå‡†å€¼é€‰æ‹©**ï¼šé€‰æ‹©æ•°ç»„ä¸­é—´å…ƒç´ ä½œä¸º pivotï¼Œæœ‰åŠ©äºåœ¨å¤šæ•°æƒ…å†µä¸‹ä¿æŒå¹³è¡¡åˆ’åˆ†ã€‚\n",
      "- **æ—¶é—´å¤æ‚åº¦**ï¼š\n",
      "  - å¹³å‡æƒ…å†µï¼š`O(n log n)`\n",
      "  - æœ€åæƒ…å†µï¼ˆå¦‚æ¯æ¬¡é€‰æ‹©æœ€å·®çš„ pivotï¼‰ï¼š`O(n^2)`ï¼Œä½†å¯ä»¥é€šè¿‡éšæœºé€‰æ‹© pivot æ”¹å–„ã€‚\n",
      "- **ç©ºé—´å¤æ‚åº¦**ï¼š`O(n)`ï¼Œå› ä¸ºä½¿ç”¨äº†é¢å¤–çš„åˆ—è¡¨å­˜å‚¨ `left`ã€`middle` å’Œ `right`ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ” å¯é€‰æ”¹è¿›ï¼šåŸåœ°æ’åºç‰ˆæœ¬\n",
      "\n",
      "å¦‚æœä½ æƒ³å®ç° **åŸåœ°æ’åºï¼ˆin-placeï¼‰** çš„å¿«é€Ÿæ’åºï¼Œå¯ä»¥ä½¿ç”¨ç±»ä¼¼ Lomuto æˆ– Hoare åˆ†åŒºçš„æ–¹å¼ã€‚è¯¥å®ç°æ›´é«˜æ•ˆï¼Œä½†ä»£ç ç•¥å¤æ‚ã€‚å¦‚æœä½ éœ€è¦è¿™ä¸ªç‰ˆæœ¬ï¼Œä¹Ÿå¯ä»¥ç»§ç»­æé—®ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ“Œ ç¤ºä¾‹è¾“å‡º\n",
      "\n",
      "è¿è¡Œä¸Šè¿°ä»£ç åï¼Œè¾“å‡ºä¸ºï¼š\n",
      "\n",
      "```\n",
      "æ’åºç»“æœ: [1, 1, 2, 3, 6, 8, 10]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "è¿™ä¸ªå®ç°éå¸¸é€‚åˆç”¨äºæ•™å­¦å’Œç†è§£å¿«é€Ÿæ’åºçš„åŸºæœ¬æ€æƒ³ã€‚å¦‚æœä½ å¸Œæœ›è¿›ä¸€æ­¥ä¼˜åŒ–ï¼ˆå¦‚éšæœºé€‰æ‹© pivotã€åŸåœ°æ’åºç­‰ï¼‰ï¼Œä¹Ÿå¯ä»¥æ ¹æ®éœ€æ±‚è¿›è¡Œè°ƒæ•´ã€‚"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen3-235B-A22B\", # ModleScope Model-Id\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': 'You are a helpful assistant.'\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'ç”¨pythonå†™ä¸€ä¸‹å¿«æ’'\n",
    "        }\n",
    "    ],\n",
    "    stream=True,\n",
    "    extra_body={\n",
    "        \"enable_thinking\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.choices[0].delta.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86fb6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.Stream at 0x7f47426c2ba0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe301729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stream :: None\n"
     ]
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "\n",
    "lite = LiteLlm(model=\"openai/Qwen/Qwen3-235B-A22B\", api_base=os.environ.get(\"OPENAI_BASE_URL\"),stream=True, api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "# lite.llm_client.chat()\n",
    "\n",
    "# openai call\n",
    "response = completion(\n",
    "    stream=True,\n",
    "    model = \"openai/Qwen/Qwen3-235B-A22B\", llm_provider=\"openai\",\n",
    "    messages=[{ \"content\": \"Hello, how are you?\",\"role\": \"user\"}]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
