{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d6658c8",
   "metadata": {},
   "source": [
    "# è¯¥è„šæœ¬ç”¨æ¥æµ‹è¯•é“¾æ¥é­”æ­apiæœåŠ¡æ˜¯å¦é€šç•…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97163dd1",
   "metadata": {},
   "source": [
    "## é€šè¿‡load dotenvåŠ è½½ç¯å¢ƒå˜é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b076350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abfaea1",
   "metadata": {},
   "source": [
    "## æŸ¥çœ‹å¯¼å…¥çš„ç¯å¢ƒå˜é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97746f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c80d92cf-e029-4240-acd1-dd89b92f5137\n",
      "https://api-inference.modelscope.cn/v1/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.environ.get(\"OPENAI_API_KEY\"))\n",
    "print(os.environ.get(\"OPENAI_BASE_URL\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e81a748",
   "metadata": {},
   "source": [
    "## è°ƒç”¨æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "161d8a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä»¥ä¸‹æ˜¯ä¸€ä¸ªç»å…¸çš„å¿«é€Ÿæ’åºï¼ˆQuick Sortï¼‰å®ç°ï¼Œä½¿ç”¨ Python ç¼–å†™ï¼Œé€‚ç”¨äºæ•™å­¦å’Œç†è§£ç›®çš„ã€‚è¯¥å®ç°é‡‡ç”¨äº†**åˆ†æ²»ç­–ç•¥**ï¼ˆDivide and Conquerï¼‰ï¼Œé€šè¿‡é€’å½’åœ°å°†æ•°ç»„åˆ’åˆ†ä¸ºè¾ƒå°çš„å­æ•°ç»„è¿›è¡Œæ’åºã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### âœ… å¿«é€Ÿæ’åºå®ç°ï¼ˆéåŸåœ°ï¼‰\n",
      "\n",
      "```python\n",
      "def quicksort(arr):\n",
      "    # å¦‚æœæ•°ç»„é•¿åº¦ä¸º0æˆ–1ï¼Œç›´æ¥è¿”å›\n",
      "    if len(arr) <= 1:\n",
      "        return arr\n",
      "    \n",
      "    # é€‰æ‹©ç¬¬ä¸€ä¸ªå…ƒç´ ä½œä¸ºåŸºå‡†ï¼ˆpivotï¼‰\n",
      "    pivot = arr[0]\n",
      "    \n",
      "    # å°†æ•°ç»„åˆ†ä¸ºä¸‰éƒ¨åˆ†ï¼šå°äºç­‰äºåŸºå‡†çš„ã€åŸºå‡†æœ¬èº«ã€å¤§äºåŸºå‡†çš„\n",
      "    left = [x for x in arr[1:] if x <= pivot]  # å·¦è¾¹å°äºç­‰äºåŸºå‡†çš„å…ƒç´ \n",
      "    right = [x for x in arr[1:] if x > pivot]  # å³è¾¹å¤§äºåŸºå‡†çš„å…ƒç´ \n",
      "    \n",
      "    # é€’å½’æ’åºå·¦å³éƒ¨åˆ†ï¼Œå¹¶å°†åŸºå‡†æ’å…¥ä¸­é—´\n",
      "    return quicksort(left) + [pivot] + quicksort(right)\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ“Œ ç¤ºä¾‹ç”¨æ³•\n",
      "\n",
      "```python\n",
      "# æµ‹è¯•æ•°ç»„\n",
      "arr = [3, 6, 8, 10, 1, 2, 1]\n",
      "\n",
      "# è°ƒç”¨å¿«é€Ÿæ’åº\n",
      "sorted_arr = quicksort(arr)\n",
      "\n",
      "# è¾“å‡ºç»“æœ\n",
      "print(sorted_arr)  # è¾“å‡º: [1, 1, 2, 3, 6, 8, 10]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ§  ç®—æ³•åŸç†\n",
      "\n",
      "1. **åŸºå‡†é€‰æ‹©**ï¼šä»æ•°ç»„ä¸­é€‰æ‹©ä¸€ä¸ªå…ƒç´ ä½œä¸ºâ€œåŸºå‡†â€ï¼ˆpivotï¼‰ã€‚\n",
      "2. **åˆ†åŒºæ“ä½œ**ï¼šå°†æ•°ç»„åˆ’åˆ†ä¸ºä¸¤ä¸ªå­æ•°ç»„ï¼š\n",
      "   - `left` åŒ…å«æ‰€æœ‰å°äºç­‰äºåŸºå‡†çš„å…ƒç´ ã€‚\n",
      "   - `right` åŒ…å«æ‰€æœ‰å¤§äºåŸºå‡†çš„å…ƒç´ ã€‚\n",
      "3. **é€’å½’æ’åº**ï¼šå¯¹ `left` å’Œ `right` å­æ•°ç»„é€’å½’æ‰§è¡Œä¸Šè¿°è¿‡ç¨‹ã€‚\n",
      "4. **åˆå¹¶ç»“æœ**ï¼šå°†æ’åºåçš„ `left`ã€åŸºå‡†ã€æ’åºåçš„ `right` æ‹¼æ¥è¿”å›ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### âš ï¸ æ—¶é—´å¤æ‚åº¦åˆ†æ\n",
      "\n",
      "| æƒ…å†µ | æ—¶é—´å¤æ‚åº¦ |\n",
      "|------|------------|\n",
      "| æœ€å¥½æƒ…å†µ | O(n log n) |\n",
      "| å¹³å‡æƒ…å†µ | O(n log n) |\n",
      "| æœ€åæƒ…å†µï¼ˆå¦‚æ•°ç»„å·²æœ‰åºï¼‰ | O(nÂ²) |\n",
      "\n",
      "> **æ³¨æ„**ï¼šåŸºå‡†é€‰æ‹©å¯¹æ€§èƒ½æœ‰è¾ƒå¤§å½±å“ã€‚ä¸Šé¢çš„å®ç°é€‰æ‹©ç¬¬ä¸€ä¸ªå…ƒç´ ä½œä¸ºåŸºå‡†ï¼Œåœ¨æœ€åæƒ…å†µä¸‹ï¼ˆå¦‚è¾“å…¥å·²æ’åºï¼‰ï¼Œæ—¶é—´å¤æ‚åº¦ä¸º O(nÂ²)ã€‚å¯ä»¥é€šè¿‡**éšæœºé€‰æ‹©åŸºå‡†**æˆ–ä½¿ç”¨**ä¸‰æ•°å–ä¸­æ³•**æ¥ä¼˜åŒ–ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ”„ å¯é€‰ä¼˜åŒ–ï¼šéšæœºé€‰æ‹©åŸºå‡†\n",
      "\n",
      "ä¸ºäº†æé«˜æ€§èƒ½ï¼Œå¯ä»¥å°†åŸºå‡†éšæœºé€‰æ‹©ï¼Œä»¥é¿å…æœ€åæƒ…å†µçš„å‘ç”Ÿï¼š\n",
      "\n",
      "```python\n",
      "import random\n",
      "\n",
      "def quicksort_optimized(arr):\n",
      "    if len(arr) <= 1:\n",
      "        return arr\n",
      "    pivot = random.choice(arr)\n",
      "    left = [x for x in arr if x < pivot]\n",
      "    middle = [x for x in arr if x == pivot]\n",
      "    right = [x for x in arr if x > pivot]\n",
      "    return quicksort_optimized(left) + middle + quicksort_optimized(right)\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ›  åŸåœ°å¿«é€Ÿæ’åºï¼ˆIn-place Quicksortï¼‰\n",
      "\n",
      "å¦‚æœä½ å¸Œæœ›å®ç°**åŸåœ°æ’åº**ï¼ˆä¸ä½¿ç”¨é¢å¤–å†…å­˜ï¼‰ï¼Œå¯ä»¥ä½¿ç”¨æŒ‡é’ˆåˆ†åŒºçš„æ–¹æ³•ï¼ˆå¦‚ Hoare æˆ– Lomuto åˆ†åŒºæ–¹æ¡ˆï¼‰ã€‚è¿™ç§å®ç°æ–¹å¼æ›´é«˜æ•ˆï¼Œä½†ä»£ç ç•¥å¤æ‚ã€‚å¦‚éœ€å®ç°ï¼Œè¯·å‘ŠçŸ¥ï¼Œæˆ‘å¯ä»¥è¿›ä¸€æ­¥æä¾›ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### âœ… æ€»ç»“\n",
      "\n",
      "- æœ¬å®ç°é€‚ç”¨äºæ•™å­¦å’Œç†è§£å¿«é€Ÿæ’åºçš„åŸºæœ¬åŸç†ã€‚\n",
      "- ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼ä½¿ä»£ç ç®€æ´æ˜“è¯»ã€‚\n",
      "- å¯¹äºå®é™…åº”ç”¨ï¼Œå»ºè®®è€ƒè™‘åŸºå‡†é€‰æ‹©ä¼˜åŒ–å’ŒåŸåœ°æ’åºå®ç°ã€‚\n",
      "\n",
      "å¦‚éœ€è¿›ä¸€æ­¥ä¼˜åŒ–æˆ–å®ç°åŸåœ°ç‰ˆæœ¬ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"c80d92cf-e029-4240-acd1-dd89b92f5137\")\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen3-235B-A22B\", # ModleScope Model-Id\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': 'You are a helpful assistant.'\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'ç”¨pythonå†™ä¸€ä¸‹å¿«æ’'\n",
    "        }\n",
    "    ],\n",
    "    stream=True,\n",
    "    extra_body={\n",
    "        \"enable_thinking\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.choices[0].delta.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e86fb6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.Stream at 0x10b2cfa10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe301729",
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "\n",
    "lite = LiteLlm(model=\"openai/Qwen/Qwen3-235B-A22B\", api_base=os.environ.get(\"OPENAI_BASE_URL\"),stream=True, api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "# lite.llm_client.chat()\n",
    "\n",
    "# openai call\n",
    "response = completion(\n",
    "    stream=True,\n",
    "    model = \"openai/Qwen/Qwen3-235B-A22B\", llm_provider=\"openai\",\n",
    "    messages=[{ \"content\": \"Hello, how are you?\",\"role\": \"user\"}]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
