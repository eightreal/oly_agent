{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d6658c8",
   "metadata": {},
   "source": [
    "# 该脚本用来测试链接魔搭api服务是否通畅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97163dd1",
   "metadata": {},
   "source": [
    "## 通过load dotenv加载环境变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b076350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abfaea1",
   "metadata": {},
   "source": [
    "## 查看导入的环境变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97746f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c80d92cf-e029-4240-acd1-dd89b92f5137\n",
      "https://api-inference.modelscope.cn/v1/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.environ.get(\"OPENAI_API_KEY\"))\n",
    "print(os.environ.get(\"OPENAI_BASE_URL\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e81a748",
   "metadata": {},
   "source": [
    "## 调用测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "161d8a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下是一个使用 Python 实现的快速排序（Quick Sort）算法，采用 **列表推导式** 的方式编写，代码简洁且易于理解，适合教学和初学者参考。\n",
      "\n",
      "---\n",
      "\n",
      "### ✅ 快速排序（Quick Sort）Python 实现\n",
      "\n",
      "```python\n",
      "def quicksort(arr):\n",
      "    if len(arr) <= 1:\n",
      "        return arr  # 基本情况：数组长度为0或1时已有序\n",
      "\n",
      "    # 选择中间元素作为基准值（pivot）\n",
      "    pivot = arr[len(arr) // 2]\n",
      "\n",
      "    # 将数组分为三部分：\n",
      "    # - 小于 pivot 的元素\n",
      "    # - 等于 pivot 的元素（用于处理重复值）\n",
      "    # - 大于 pivot 的元素\n",
      "    left = [x for x in arr if x < pivot]\n",
      "    middle = [x for x in arr if x == pivot]\n",
      "    right = [x for x in arr if x > pivot]\n",
      "\n",
      "    # 递归排序左右部分，并将结果合并\n",
      "    return quicksort(left) + middle + quicksort(right)\n",
      "\n",
      "# 测试用例\n",
      "if __name__ == \"__main__\":\n",
      "    arr = [3, 6, 8, 10, 1, 2, 1]\n",
      "    sorted_arr = quicksort(arr)\n",
      "    print(\"排序结果:\", sorted_arr)\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### 🧠 算法说明\n",
      "\n",
      "- **分治策略**：将数组划分为三部分（小于、等于、大于基准值），递归排序左右部分。\n",
      "- **基准值选择**：选择数组中间元素作为 pivot，有助于在多数情况下保持平衡划分。\n",
      "- **时间复杂度**：\n",
      "  - 平均情况：`O(n log n)`\n",
      "  - 最坏情况（如每次选择最差的 pivot）：`O(n^2)`，但可以通过随机选择 pivot 改善。\n",
      "- **空间复杂度**：`O(n)`，因为使用了额外的列表存储 `left`、`middle` 和 `right`。\n",
      "\n",
      "---\n",
      "\n",
      "### 🔁 可选改进：原地排序版本\n",
      "\n",
      "如果你想实现 **原地排序（in-place）** 的快速排序，可以使用类似 Lomuto 或 Hoare 分区的方式。该实现更高效，但代码略复杂。如果你需要这个版本，也可以继续提问。\n",
      "\n",
      "---\n",
      "\n",
      "### 📌 示例输出\n",
      "\n",
      "运行上述代码后，输出为：\n",
      "\n",
      "```\n",
      "排序结果: [1, 1, 2, 3, 6, 8, 10]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "这个实现非常适合用于教学和理解快速排序的基本思想。如果你希望进一步优化（如随机选择 pivot、原地排序等），也可以根据需求进行调整。"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"c80d92cf-e029-4240-acd1-dd89b92f5137\")\n",
    "\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"random_float\",\n",
    "            \"description\": \"get a random float\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {},\n",
    "                \"required\": [],\n",
    "                \"additionalProperties\": False,\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen3-235B-A22B\",  # ModleScope Model-Id\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"生成一个随机float\"},\n",
    "    ],\n",
    "    stream=True,\n",
    "    extra_body={\n",
    "        \"enable_thinking\": False,\n",
    "    },\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86fb6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.Stream at 0x7f47426c2ba0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe301729",
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "import os\n",
    "\n",
    "\n",
    "lite = LiteLlm(\n",
    "    model=\"openai/Qwen/Qwen3-235B-A22B\",\n",
    "    api_base=os.environ.get(\"OPENAI_BASE_URL\"),\n",
    "    stream=True,\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "# lite.llm_client.chat()\n",
    "\n",
    "# openai call\n",
    "response = completion(\n",
    "    stream=True,\n",
    "    model=\"openai/Qwen/Qwen3-235B-A22B\",\n",
    "    llm_provider=\"openai\",\n",
    "    messages=[{\"content\": \"Hello, how are you?\", \"role\": \"user\"}],\n",
    "    extra_body={\n",
    "        \"enable_thinking\": True,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d646a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.Stream at 0x7f758e2c6ad0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.fetch_sync_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1a53831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f441f855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "\n",
    "res = litellm.completion(\n",
    "    model=\"openai/Qwen/Qwen3-235B-A22B\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"developer\",\n",
    "            \"content\": '\\n 你是一个负责审核文案是否包含敏感词的agent，请检查输入的文案是否包含敏感词，\\n 如果包含敏感词，请返回敏感词，并解释，否则返回\"no sensitive word\"。\\n    请关注如下但不仅限于以下的敏感词：\\n    1. 政治敏感词\\n    2. 宗教敏感词\\n    3. 暴力敏感词\\n    4. 暴力恐吓敏感词\\n    5. 色情敏感词\\n    6. 舆论对立敏感词\\n 如果输入的文案中不包含敏感词，那么请返回\"no sensitive word\"。\\n\\n\\nYou are an agent. Your internal name is \"sensitive_word\".\\n\\n The description about you is \"一个负责敏感词检测的agent\"\\n\\n\\nYou have a list of other agents to transfer to:\\n\\n\\nAgent name: root_agent\\nAgent description: 一个广告以及文案的内容审核助手\\n\\n\\nAgent name: wrong_word\\nAgent description: 一个负责文案错别字检测的agent\\n\\n\\nIf you are the best to answer the question according to your description, you\\ncan answer it.\\n\\nIf another agent is better for answering the question according to its\\ndescription, call `transfer_to_agent` function to transfer the\\nquestion to that agent. When transferring, do not generate any text other than\\nthe function call.\\n\\nYour parent agent is root_agent. If neither the other agents nor\\nyou are best for answering the question according to the descriptions, transfer\\nto your parent agent. If you don\\'t have parent agent, try answer by yourself.\\n',\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"欧莱雅新品发售\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"For context:\"},\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"[root_agent] called tool `transfer_to_agent` with parameters: {'agent_name': 'sensitive_word'}\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"For context:\"},\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"[root_agent] `transfer_to_agent` tool returned result: {}\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"transfer_to_agent\",\n",
    "                \"description\": \"Transfer the question to another agent.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\"agent_name\": {\"type\": \"string\"}},\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "    stream=True,\n",
    "    api_base=None,\n",
    "    api_key=\"ee879477-517c-4899-9793-de2b20aad7ba\",\n",
    "    extra_body={\"enable_thinking\": True, \"stream\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47935f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34866a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<litellm.litellm_core_utils.streaming_handler.CustomStreamWrapper at 0x7f135fa282d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = litellm.completion(\n",
    "    model=\"openai/Qwen/Qwen3-235B-A22B\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"developer\",\n",
    "            \"content\": 'You are an expert delegator that can delegate the user request to the\\nappropriate remote agents.\\n\\nTaskDescription:\\n你需要使用你的agents来执行文案审核的内容，同时你需要使用它们的返回结果并最终总返回结果 ，\\n如果可以请同时调用所有的agents\\n\\n\\nDiscovery:\\n- You can use `list_agents` to list the available remote agents you\\ncan use to delegate the task.\\n\\nExecution:\\n- For actionable requests, you can use `send_message` to interact with remote agents to take action.\\n- 在总结之前你需要考虑是否已经完全调用了你的所有agents\\n\\nBe sure to include the remote agent name when you respond to the user.\\n\\nPlease rely on tools to address the request, and don\\'t make up the response. If you are not sure, please ask the user for more details.\\nFocus on the most recent parts of the conversation primarily.\\n\\n\\n\\n\\n\\nYou are an agent. Your internal name is \"root_agent\".\\n\\n The description about you is \"一个广告以及文案的内容审核助手\"\\n\\n\\nYou have a list of other agents to transfer to:\\n\\n\\nAgent name: sensitive_word\\nAgent description: 一个负责敏感词检测的agent\\n\\n\\nAgent name: wrong_word\\nAgent description: 一个负责文案错别字检测的agent\\n\\n\\nIf you are the best to answer the question according to your description, you\\ncan answer it.\\n\\nIf another agent is better for answering the question according to its\\ndescription, call `transfer_to_agent` function to transfer the\\nquestion to that agent. When transferring, do not generate any text other than\\nthe function call.\\n',\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"欧莱雅新品发售\"},\n",
    "    ],\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"transfer_to_agent\",\n",
    "                \"description\": \"Transfer the question to another agent.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\"agent_name\": {\"type\": \"string\"}},\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "    stream=True,\n",
    "    api_base=None,\n",
    "    api_key=\"ee879477-517c-4899-9793-de2b20aad7ba\",\n",
    "    extra_body={\"enable_thinking\": True, \"stream\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f5cf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
